{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30P3b2SyFDe_",
        "outputId": "bdaa97e6-1f4e-4e0b-a900-238213e71612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "_l8BTxGiFJL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_file_names(s):\n",
        "  x = os.path.splitext(s)[0]\n",
        "  x = x.split('/')\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "iYsN-z0ESxCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(filename):\n",
        "  with open(filename) as file:\n",
        "    lines = [line.rstrip() for line in file]\n",
        "\n",
        "  return lines"
      ],
      "metadata": {
        "id": "tCq4QJ5uUYdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = ... # add base path\n",
        "countries=[...] # add country\n",
        "for c in countries:\n",
        "  results = list()\n",
        "  print(c)\n",
        "  folders = glob.glob(f\"{base_path}/{c}/*/*/*-standard.txt\")\n",
        "  for i in folders:\n",
        "    split_names = split_file_names(i)\n",
        "    #print(split_names)\n",
        "    #break\n",
        "    country = split_names[0]\n",
        "    cab = split_names[1]\n",
        "    pol_area = split_names[2]\n",
        "\n",
        "    contents = read_file(i)\n",
        "    for idx, j in enumerate(contents):\n",
        "      mp_cmp_score = j.split('\\t')\n",
        "      mp_cmp = mp_cmp_score[0].split('__')\n",
        "      if len(mp_cmp) <= 1:\n",
        "        mp = mp_cmp[0]\n",
        "        score = mp_cmp_score[1]\n",
        "\n",
        "        results.append((cab,mp,pol_area,'',score))\n",
        "\n",
        "      else:\n",
        "\n",
        "        #print(mp_cmp)  )\n",
        "        mp = mp_cmp[0]\n",
        "        CMP = mp_cmp[1]\n",
        "        #ep = mp_cmp[2]\n",
        "        score = mp_cmp_score[1]\n",
        "\n",
        "      results.append((cab,mp,pol_area,CMP,score))\n",
        "  #break\n",
        "  df = pd.DataFrame(results,columns=['cabinet', 'speaker', 'policyarea', 'partyfacts', 'scaled_score'])\n",
        "  #print(df)\n",
        "  df.to_csv(f'{c}_mp_scaling_scores_normalized.csv', sep=',', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "PhhrnBnUTGz5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}